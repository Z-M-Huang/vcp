---
id: core-testing
title: Testing
scope: core
severity: high
tags: [testing, mocking, behavior, edge-cases, tdd, boundaries]
references:
  - title: "Martin Fowler — Mocks Aren't Stubs"
    url: https://martinfowler.com/articles/mocksArentStubs.html
  - title: "Google Testing Blog — Testing on the Toilet"
    url: https://testing.googleblog.com/
---

## Principle

Tests exist to catch regressions — to tell you when working code breaks. A test that cannot fail provides zero value. A test that breaks when you refactor (without changing behavior) provides negative value. Tests must verify **what** the code does, not **how** it does it.

AI-generated tests "test their own assumptions rather than developer intent." Coverage metrics look good but edge cases, domain constraints, and integration boundaries are missing. Over-mocking is the primary failure mode: AI mocks internal dependencies that should be tested through, producing tests that verify mock wiring instead of real logic.

## Rules

### Test Behavior, Not Implementation

1. **Test observable outcomes, not internal mechanics.** A test should assert on return values, side effects visible to the caller, state changes, or emitted events. It should not assert on which internal methods were called, in what order, or how many times. Tests that depend on implementation break during refactoring even when behavior is preserved.

2. **Write tests that describe expected behavior in their names.** Test names should read as specifications: "returns empty list when user has no orders", "throws ValidationError when email is missing", "sends confirmation email after successful payment." Do not name tests after method names: "testCreateUser", "test_calculate", "it should work."

3. **Avoid tautological tests.** A test that asserts the code does what it does (rather than what it should do) catches nothing. If the test was generated by reading the implementation and asserting the same logic, it will pass even when the logic is wrong. Write tests from the requirement, not from the code.

### Mocking Discipline

4. **Mock external services, not internal logic.** Mock the boundaries of your system: HTTP APIs, databases, file systems, message queues, third-party SDKs, system clocks. Do not mock your own classes, services, or utility functions. If you mock internal logic, you're testing that the mock is wired correctly — not that the system works.

5. **When you mock, verify the contract — not the call.** If you mock a payment gateway, assert that the mock was called with the correct amount, currency, and idempotency key. Do not assert that it was called exactly once, in a specific order, after another mock — unless that ordering is part of the contract.

6. **Prefer fakes over mocks for complex dependencies.** For dependencies with complex behavior (databases, caches, queues), use in-memory fakes that implement the same interface with real logic. Fakes catch more bugs than mocks because they exercise real behavior patterns (e.g., an in-memory repository that enforces unique constraints).

### Boundary Testing

7. **Test edge cases explicitly.** For every input, test: null/undefined/missing, empty string/array/object, zero, negative values, maximum values, boundary values (off-by-one), malformed input, and unicode/special characters. AI consistently skips these — they are where real bugs hide.

8. **Test error paths, not just happy paths.** For every operation that can fail — network calls, file access, parsing, validation — write tests that verify the failure behavior: correct error type, correct error message, correct cleanup/rollback, and that partial state is not persisted.

### Test Independence

9. **Each test must be independent and self-contained.** Tests must not depend on execution order, shared mutable state, or side effects from other tests. A test that passes alone but fails in a suite (or vice versa) is broken. Use fresh fixtures for each test.

10. **Tests must be deterministic.** No test should depend on the current time, random values, network availability, or filesystem state that isn't set up by the test itself. Inject time and randomness; use test fixtures for filesystem state.

### Test Value

11. **Delete tests that provide no signal.** A test that always passes regardless of code changes is dead weight. A test that is so brittle it breaks on every change gets ignored. Both reduce trust in the test suite. Remove them and write tests that catch real regressions.

12. **Prefer fewer meaningful tests over many trivial ones.** One test that exercises a real user flow through validation, business logic, and persistence catches more bugs than ten tests that each assert one getter returns a value. Integration tests at service boundaries are worth more than unit tests of trivial methods.

## Patterns

### Test Behavior, Not Implementation

#### Do This

```python
# Tests the observable behavior: what goes in, what comes out
def test_apply_discount_reduces_total():
    order = Order(items=[Item(price=100, quantity=2)])
    order.apply_discount(percent=10)
    assert order.total == 180  # Observable outcome

def test_apply_discount_rejects_negative_percent():
    order = Order(items=[Item(price=100, quantity=1)])
    with pytest.raises(ValueError, match="percent must be 0-100"):
        order.apply_discount(percent=-5)
```

#### Not This

```python
# Tests internal implementation details — breaks on refactoring
def test_apply_discount_calls_calculate(mocker):
    order = Order(items=[Item(price=100, quantity=2)])
    spy = mocker.spy(order, "_calculate_total")
    order.apply_discount(percent=10)
    spy.assert_called_once()  # Testing HOW, not WHAT
    # If _calculate_total is renamed or inlined, this test breaks
    # even though the discount behavior is unchanged
```

**Why it's wrong:** The test asserts that an internal method `_calculate_total` was called. This is an implementation detail — if the calculation is inlined, moved to a helper, or renamed, the test breaks even though the discount behavior works correctly. The test protects the implementation, not the behavior.

### Mock External, Not Internal

#### Do This

```python
# Mock the external boundary (payment API), test real internal logic
def test_place_order_charges_correct_amount(mock_payment_gateway):
    mock_payment_gateway.charge.return_value = PaymentResult(success=True)

    # Real order service, real validator, real calculator — only gateway is mocked
    service = OrderService(
        validator=OrderValidator(),       # Real
        calculator=PriceCalculator(),     # Real
        payment=mock_payment_gateway,     # Mocked — external service
    )

    service.place_order(items=[Item(price=50, qty=2)], currency="USD")

    mock_payment_gateway.charge.assert_called_with(
        amount=100, currency="USD"
    )
```

#### Not This

```python
# Everything mocked — testing mock wiring, not real logic
def test_place_order(mock_validator, mock_calculator, mock_payment, mock_repo):
    mock_validator.validate.return_value = []
    mock_calculator.calculate.return_value = 100
    mock_payment.charge.return_value = PaymentResult(success=True)
    mock_repo.save.return_value = Order(id=1)

    service = OrderService(mock_validator, mock_calculator, mock_payment, mock_repo)
    result = service.place_order(items=[Item(price=50, qty=2)])

    mock_validator.validate.assert_called_once()
    mock_calculator.calculate.assert_called_once()
    mock_payment.charge.assert_called_once_with(amount=100)
    mock_repo.save.assert_called_once()
```

**Why it's wrong:** Every internal dependency is mocked. The test verifies that `place_order` calls four methods in sequence — not that the order is validated correctly, the price is calculated correctly, or the payment amount is right. If the calculator has a bug that returns the wrong total, this test still passes because the calculator is mocked.

### Edge Case Testing

#### Do This

```python
def test_search_with_empty_query():
    assert search("") == []

def test_search_with_none_query():
    with pytest.raises(TypeError):
        search(None)

def test_search_with_special_characters():
    # Should not crash or produce SQL injection
    results = search("'; DROP TABLE users; --")
    assert isinstance(results, list)

def test_search_with_unicode():
    results = search("café résumé naïve")
    assert isinstance(results, list)

def test_search_with_max_length_query():
    results = search("a" * 10000)
    assert isinstance(results, list)  # Should handle gracefully
```

#### Not This

```python
# Only tests the happy path
def test_search():
    results = search("python")
    assert len(results) > 0
```

**Why it's wrong:** Only the happy path is tested. In production, users submit empty queries, paste special characters, use unicode, and send unexpectedly long strings. Every one of these is a potential crash, injection vector, or incorrect behavior that this test suite would not catch.

### Test Naming

#### Do This

```python
# Names describe expected behavior
def test_returns_empty_list_when_user_has_no_orders(): ...
def test_raises_validation_error_when_email_is_missing(): ...
def test_sends_confirmation_email_after_successful_payment(): ...
def test_applies_bulk_discount_for_orders_over_ten_items(): ...
```

#### Not This

```python
# Names describe methods, not behavior
def test_get_orders(): ...
def test_create_user(): ...
def test_process_payment(): ...
def test_calculate_discount(): ...
```

**Why it's wrong:** `test_get_orders` doesn't tell you what behavior is being verified. Does it test the happy path? The empty case? Error handling? When the test fails, the name gives no hint about what expectation was violated. Behavior-descriptive names serve as living documentation.

## Exceptions

- **Trivial getters/setters** don't need tests. If a method returns a field value with no logic, testing it adds noise without value.
- **Third-party library behavior** should not be tested by your test suite. Test your code's interaction with the library, not the library itself.
- **Test utilities and fixtures** may share state within a test module for setup efficiency, as long as each test gets a fresh copy (e.g., via `setUp`/`beforeEach`).

## Cross-References

- [Error Handling](core-error-handling) — What error behavior tests should verify
- [Security](core-security) — Security boundary testing requirements
- [Code Quality](core-code-quality) — When test duplication is acceptable
